{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "nWr0tWTUvHw7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "OF9HL8Vb59EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swHikdY0-2Z4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HBymUDft1kt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "Vt-D2C4Fq6EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/NSC/Data Set/DataSet LSTM/DataSet LSTM.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "metadata": {
        "id": "Ob7xyaGF_3nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions = np.array(['Hello', 'Hungry', 'Sick', 'Sorry', 'Thank you', 'What', 'When', 'Where', 'Who', 'Why'])\n",
        "label_map = {label:num for num, label in enumerate(actions)}\n",
        "label_map"
      ],
      "metadata": {
        "id": "yJCrZVky_-H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = 30\n",
        "sequence_length = 30\n",
        "DATA_PATH = os.path.join(\"/content\")\n",
        "print(DATA_PATH)"
      ],
      "metadata": {
        "id": "s1ns5LyDAAgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences, labels = [], []\n",
        "for action in actions:\n",
        "  for num in range(folder):\n",
        "    window = []\n",
        "    for frame_num in range(sequence_length):\n",
        "      res = np.load(os.path.join(DATA_PATH, action, str(num), \"{}.npy\".format(frame_num)))\n",
        "      window.append(res)\n",
        "    sequences.append(window)\n",
        "    labels.append(label_map[action])\n",
        "  print(action)"
      ],
      "metadata": {
        "id": "oE8FRwnDAEVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(sequences)\n",
        "y = np.array(labels)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "mTp-RnOwAGVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "mb_x0eFtuDsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "A4JZYfbVmchk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, 258)))\n",
        "model.add(LSTM(128, input_shape=(30, 258), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4WlvkxfpJwXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model-lstm.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "EhNp0_BkZ355"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, 258)))\n",
        "model.add(LSTM(128, input_shape=(30, 258), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "num_folds = 5\n",
        "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "fold = 0\n",
        "models = []\n",
        "cos_mat = []\n",
        "report = []\n",
        "for train_indices, val_indices in tqdm(skf.split(X, y)):\n",
        "    fold += 1\n",
        "    print(f'Fold: {fold}')\n",
        "\n",
        "    log_dir = os.path.join('Logs_{0}'.format(fold))\n",
        "    tb_callback = TensorBoard(log_dir=log_dir)\n",
        "\n",
        "    y_c = to_categorical(y).astype(int)\n",
        "    X_train, X_val = X[train_indices], X[val_indices]\n",
        "    y_train, y_val = y_c[train_indices], y_c[val_indices]\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=150, callbacks=[TensorBoard(log_dir='./log')], validation_data=(X_val, y_val), batch_size=64, verbose=0)\n",
        "\n",
        "    loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f'Validation loss: {loss}, Validation accuracy: {accuracy}')\n",
        "\n",
        "    y_nn = model.predict(X_val)\n",
        "    models.append(model)\n",
        "    cos_mat.append(confusion_matrix(actions[y_val.argmax(axis=1)], actions[y_nn.argmax(axis=1)]))\n",
        "    report.append(classification_report(actions[y_val.argmax(axis=1)], actions[y_nn.argmax(axis=1)]))\n",
        "    model.reset_states()"
      ],
      "metadata": {
        "id": "VIrqFNFemfD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, 258)))\n",
        "model.add(LSTM(128, input_shape=(30, 258), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "model.fit(X_train, y_train, epochs=150, validation_data=(X_val, y_val), batch_size=64, verbose=1)"
      ],
      "metadata": {
        "id": "qg1mUIoRDZbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "FHwsIkcJudgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 5\n",
        "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)"
      ],
      "metadata": {
        "id": "tx2XavdHWV-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_mat = []\n",
        "models = []\n",
        "\n",
        "num = 1\n",
        "for train_indices, val_indices in skf.split(X, y):\n",
        "  model = load_model('/content/drive/MyDrive/NSC/Model/LSTM/Model_LSTM_{0}.h5'.format(num))\n",
        "  num += 1\n",
        "  models.append(model)\n",
        "  y_c = to_categorical(y).astype(int)\n",
        "  X_train, X_val = X[train_indices], X[val_indices]\n",
        "  y_train, y_val = y_c[train_indices], y_c[val_indices]\n",
        "  y_nn = model.predict(X_val)\n",
        "  cos_mat.append(confusion_matrix(actions[y_val.argmax(axis=1)], actions[y_nn.argmax(axis=1)]))\n",
        "  loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "  print(f'Validation loss: {loss}, Validation accuracy: {accuracy}')\n",
        "  print('')"
      ],
      "metadata": {
        "id": "mqjB4y8HIs3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = np.array(['Hello', 'Hungry', 'Sick', 'Sorry', 'Thank you', 'What', 'When', 'Where', 'Who', 'Why'])\n",
        "word"
      ],
      "metadata": {
        "id": "dkTBFnB2ZvhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "1ZdWfYMWxqWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cos_mat[0], annot=True, cmap='RdPu')\n",
        "plt.xticks(range(len(cos_mat[0])), word)\n",
        "plt.yticks(range(len(cos_mat[0])), word)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FND22ov4xVMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report[0])"
      ],
      "metadata": {
        "id": "gy7U-jZpxcBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models[0].save('/content/drive/MyDrive/NSC/Model/LSTM/Model_LSTM_1.h5')"
      ],
      "metadata": {
        "id": "S1WTyCxiH6jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "hsg3J8YQx-KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cos_mat[1], annot=True, cmap='RdPu')\n",
        "plt.xticks(range(len(cos_mat[1])), word)\n",
        "plt.yticks(range(len(cos_mat[1])), word)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J_02fOEdx74u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report[1])"
      ],
      "metadata": {
        "id": "94sCy7POx74w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models[1].save('/content/drive/MyDrive/NSC/Model/LSTM/Model_LSTM_2.h5')"
      ],
      "metadata": {
        "id": "ecNquwzPx74w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "YxnSfxVRyJrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cos_mat[2], annot=True, cmap='RdPu')\n",
        "plt.xticks(range(len(cos_mat[2])), word)\n",
        "plt.yticks(range(len(cos_mat[2])), word)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UQ5QgrkeyIE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report[2])"
      ],
      "metadata": {
        "id": "_pLf82GnyIFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models[2].save('/content/drive/MyDrive/NSC/Model/LSTM/Model_LSTM_3.h5')"
      ],
      "metadata": {
        "id": "Fqy98XOLyIFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4"
      ],
      "metadata": {
        "id": "8Rh6HNPRyccW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cos_mat[3], annot=True, cmap='RdPu')\n",
        "plt.xticks(range(len(cos_mat[3])), word)\n",
        "plt.yticks(range(len(cos_mat[3])), word)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "82xNR1cQyelI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report[3])"
      ],
      "metadata": {
        "id": "oJ6ABPFvyelT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models[3].save('/content/drive/MyDrive/NSC/Model/LSTM/Model_LSTM_4.h5')"
      ],
      "metadata": {
        "id": "0NLJAjcIyelT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5"
      ],
      "metadata": {
        "id": "7pSJDC-NylDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cos_mat[4], annot=True, cmap='RdPu')\n",
        "plt.xticks(range(len(cos_mat[4])), word)\n",
        "plt.yticks(range(len(cos_mat[4])), word)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pXDF50qSym-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report[4])"
      ],
      "metadata": {
        "id": "XHKYulDKym_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models[4].save('/content/drive/MyDrive/NSC/Model/LSTM/Model_LSTM_5.h5')"
      ],
      "metadata": {
        "id": "VQN0wuAdym_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment"
      ],
      "metadata": {
        "id": "nWr0tWTUvHw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp_holistic = mp.solutions.holistic\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image.flags.writeable = False\n",
        "    results = model.process(image)\n",
        "    image.flags.writeable = True\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    return image, results\n",
        "\n",
        "def draw_landmarks(image, results):\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "\n",
        "def draw_styled_landmarks(image, results):\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "\n",
        "def extract_keypoints(results):\n",
        "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
        "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
        "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
        "    return np.concatenate([pose, lh, rh])"
      ],
      "metadata": {
        "id": "CQUTlsME0ozD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "fw5_szj49AFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions = np.array(['Hello', 'Hungry', 'Sick', 'Sorry', 'Thank you', 'What', 'When', 'Where', 'Who', 'Why'])"
      ],
      "metadata": {
        "id": "u8Wyo2-h_Ha5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/NSC/Model/Model_LSTM.h5')"
      ],
      "metadata": {
        "id": "uWrlqt5aRUdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hello"
      ],
      "metadata": {
        "id": "gfZb43ml_Ndf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = []\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "  cap = cv2.VideoCapture(\"/content/drive/MyDrive/NSC/Data Set/datasets clip/Hello 30 clip/IMG_3830.MOV\")\n",
        "  n = 0\n",
        "  while True:\n",
        "    n += 1\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "      frame = cv2.resize(frame, (800, 480))\n",
        "      image, results = mediapipe_detection(frame, holistic)\n",
        "      draw_styled_landmarks(image, results)\n",
        "      keypoints = extract_keypoints(results)\n",
        "      sequence.append(keypoints)\n",
        "      sequence = sequence[-30:]\n",
        "      if len(sequence) == 30:\n",
        "        res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
        "        name = actions[np.argmax(res)]\n",
        "        cal = res[np.argmax(res)] * 100\n",
        "        if cal <= 50:\n",
        "          name = \"Do not know\"\n",
        "        cv2.putText(image, name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 2)\n",
        "        cv2.putText(image, str('%.2f' %(cal)) + \" %\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "        cv2_imshow(image)\n",
        "    if (cv2.waitKey(1) & 0xFF == ord('q')) or not ret:\n",
        "      break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "S1kR8J8P2BmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorry"
      ],
      "metadata": {
        "id": "tCKjaSRl_02x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = []\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "  cap = cv2.VideoCapture(\"/content/drive/MyDrive/NSC/Data Set/datasets clip/Sorry 30 clip/30.mov\")\n",
        "  n = 0\n",
        "  while True:\n",
        "    n += 1\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "      frame = cv2.resize(frame, (800, 480))\n",
        "      image, results = mediapipe_detection(frame, holistic)\n",
        "      draw_styled_landmarks(image, results)\n",
        "      keypoints = extract_keypoints(results)\n",
        "      sequence.append(keypoints)\n",
        "      sequence = sequence[-30:]\n",
        "      if len(sequence) == 30:\n",
        "        res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
        "        name = actions[np.argmax(res)]\n",
        "        cal = res[np.argmax(res)] * 100\n",
        "        if cal <= 50:\n",
        "          name = \"Do not know\"\n",
        "        cv2.putText(image, name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 2)\n",
        "        cv2.putText(image, str('%.2f' %(cal)) + \" %\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "        cv2_imshow(image)\n",
        "    if (cv2.waitKey(1) & 0xFF == ord('q')) or not ret:\n",
        "      break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "G3Rw9J9H_RO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank you"
      ],
      "metadata": {
        "id": "9tfgW1iL_6u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = []\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "  cap = cv2.VideoCapture(\"/content/drive/MyDrive/NSC/Data Set/datasets clip/Thank you 30 clip/IMG_3842.MOV\")\n",
        "  n = 0\n",
        "  while True:\n",
        "    n += 1\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "      frame = cv2.resize(frame, (800, 480))\n",
        "      image, results = mediapipe_detection(frame, holistic)\n",
        "      draw_styled_landmarks(image, results)\n",
        "      keypoints = extract_keypoints(results)\n",
        "      sequence.append(keypoints)\n",
        "      sequence = sequence[-30:]\n",
        "      if len(sequence) == 30:\n",
        "        res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
        "        name = actions[np.argmax(res)]\n",
        "        cal = res[np.argmax(res)] * 100\n",
        "        if cal <= 50:\n",
        "          name = \"Do not know\"\n",
        "        cv2.putText(image, name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 2)\n",
        "        cv2.putText(image, str('%.2f' %(cal)) + \" %\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "        cv2_imshow(image)\n",
        "    if (cv2.waitKey(1) & 0xFF == ord('q')) or not ret:\n",
        "      break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "IyxwKrw6AAhS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}